{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "import pandas as pd\n",
    "import time \n",
    "import bokeh \n",
    "import numpy as np\n",
    "import binascii\n",
    "import redis\n",
    "import pprint\n",
    "import json\n",
    "import qgrid\n",
    "import matplotlib.pyplot as plt\n",
    "pp = pprint.PrettyPrinter() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def example(x):\n",
    "    return \"ok\" \n",
    "\n",
    "@ray.remote\n",
    "def example2(x): \n",
    "    return \"hi\"\n",
    "\n",
    "@ray.remote\n",
    "class TestCls():\n",
    "    def __init__(self):\n",
    "        self.g = 1\n",
    "        \n",
    "    def to_go(self, x):\n",
    "        return x\n",
    "\n",
    "    \n",
    "@ray.remote\n",
    "class Outer():\n",
    "    def __init__(self):\n",
    "        self.f = 1\n",
    "        self.test = TestCls.remote()\n",
    "    \n",
    "    def to_go2(self, x):\n",
    "        return x * 2\n",
    "    \n",
    "    def error(self):\n",
    "        return 1/0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data in Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "ename": "RayConnectionError",
     "evalue": "This command cannot be called before Ray has been started. You can start Ray with 'ray.init()'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2380c7b6b12a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Here, we generate data in redis for remote tasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"here\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"here2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresults2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2380c7b6b12a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Here, we generate data in redis for remote tasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"here\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"here2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresults2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michellemarzoev/Desktop/ray/python/ray/worker.py\u001b[0m in \u001b[0;36mfunc_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1989\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mfunc_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1990\u001b[0m         \u001b[0;34m\"\"\"This gets run immediately when a worker calls a remote function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1991\u001b[0;31m         \u001b[0mcheck_connected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1992\u001b[0m         \u001b[0mcheck_main_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1993\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_signature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michellemarzoev/Desktop/ray/python/ray/worker.py\u001b[0m in \u001b[0;36mcheck_connected\u001b[0;34m(worker)\u001b[0m\n\u001b[1;32m    599\u001b[0m   \"\"\"\n\u001b[1;32m    600\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnected\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m     raise RayConnectionError(\"This command cannot be called before Ray has \"\n\u001b[0m\u001b[1;32m    602\u001b[0m                              \u001b[0;34m\"been started. You can start Ray with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                              \"'ray.init()'.\")\n",
      "\u001b[0;31mRayConnectionError\u001b[0m: This command cannot be called before Ray has been started. You can start Ray with 'ray.init()'."
     ]
    }
   ],
   "source": [
    "# Here, we generate data in redis for remote tasks\n",
    "print(\"here\")\n",
    "results = ray.get([example.remote(x) for x in range(4000)])\n",
    "print(\"here2\")\n",
    "results2 = ray.get([example2.remote(x) for x in range(2000)])\n",
    "print(\"here3\")\n",
    "# Generating data for Actor tasks\n",
    "actor = TestCls.remote()\n",
    "actor_results = ray.get([actor.to_go.remote(1)])\n",
    "\n",
    "err_actor = Outer.remote()\n",
    "err_actor.error.remote()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "addr, port = ray.worker.global_worker.redis_address.split(\":\")\n",
    "rc = redis.StrictRedis(host=addr, port=port, decode_responses=True, encoding='latin-1', encoding_errors='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Jobs Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remote Functions Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f7ae995a0f4f6285edc20c2c2f1716"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fn_table = ray.global_state.function_table()\n",
    "fn_list = []\n",
    "for fn_id in fn_table:\n",
    "    val = fn_table[fn_id]\n",
    "    val[\"function_id\"] = fn_id\n",
    "    fn_list.append(val)\n",
    "qgrid.nbinstall(overwrite = True)\n",
    "qgrid.show_grid(pd.DataFrame(fn_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133d581139c14f809137ef95d0a32f9e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas.io.json import json_normalize\n",
    "\n",
    "tt = ray.global_state.task_table()\n",
    "tt_list = list(tt.values())\n",
    "tt_list\n",
    "\n",
    "for d in tt_list:\n",
    "    d['TaskSpec']['ReturnObjectIDs'] = [oid.hex() for oid in d['TaskSpec']['ReturnObjectIDs']]\n",
    "\n",
    "task_df = json_normalize(tt_list)\n",
    "qgrid.show_grid(task_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actor Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actor_info = dict()\n",
    "actors = rc.keys(\"Actor*\") \n",
    "for actor in actors:\n",
    "    actor_key_str = actor[len('Actor:'):]\n",
    "    actor_key_bytes = actor_key_str.encode('latin-1')\n",
    "    actor_info['Actor:{}'.format(hex_identifier(actor_key_bytes))] = rc.hgetall(actor)\n",
    "    x = actor_info['Actor:{}'.format(hex_identifier(actor_key_bytes))]\n",
    "    if 'class_id' in x: \n",
    "        class_key_bytes = x['class_id'].encode('latin-1')\n",
    "        x['class_id'] = format(hex_identifier(class_key_bytes))\n",
    "    if 'driver_id' in x: \n",
    "        driver_bytes = x['driver_id'].encode('latin-1')\n",
    "        x['driver_id'] = format(hex_identifier(driver_bytes))\n",
    "\n",
    "actor_df = pd.DataFrame.from_dict(actor_info)\n",
    "qgrid.show_grid(actor_df.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - Worker Placement Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event_names = rc.keys(\"event_log*\")\n",
    "results = dict()\n",
    "for i in range(len(event_names)):\n",
    "    event_list = rc.lrange(event_names[i], 0, -1)\n",
    "    for event in event_list:\n",
    "        event_dict = json.loads(event)\n",
    "        task_id = \"\"\n",
    "        worker_id = \"\"\n",
    "        function_name = \"\"\n",
    "    for element in event_dict:\n",
    "        if \"task_id\" in element[3] and \"worker_id\" in element[3]:\n",
    "            task_id = element[3][\"task_id\"]\n",
    "            worker_id = element[3][\"worker_id\"]\n",
    "            function_name = element[3][\"function_name\"]\n",
    "        if task_id != \"\" and worker_id != \"\" and function_name != \"\":\n",
    "            results[worker_id] = {}\n",
    "            results[worker_id][\"task_id\"] = task_id\n",
    "            results[worker_id][\"function_name\"] = function_name\n",
    "results_table = pd.DataFrame.from_dict(results)\n",
    "qgrid.show_grid(results_table.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "task_profiles, events = ray.global_state.task_profiles()\n",
    "profiles_dict = dict()\n",
    "for task_id, profiles in task_profiles.items(): \n",
    "    for profile in profiles:\n",
    "        start_exec = -1\n",
    "        end_exec = -1 \n",
    "        start_store = -1\n",
    "        end_store = -1\n",
    "        start_lock = -1\n",
    "        end_lock = -1\n",
    "        overall_start = profile[0][0]\n",
    "        overall_end = profile[len(profile)-1][0]\n",
    "        overall_dur = overall_end - overall_start\n",
    "        for log in profile: \n",
    "            if log[1] == \"ray:task:execute\" and log[2] == 1: \n",
    "                start_exec = log[0]\n",
    "            if log[1] == \"ray:task:execute\" and log[2] == 2: \n",
    "                end_exec = log[0]\n",
    "            if log[1] == \"ray:task:store_outputs\" and log[2] == 1: \n",
    "                start_store = log[0]\n",
    "            if log[1] == \"ray:task:store_outputs\" and log[2] == 2: \n",
    "                end_store = log[0]\n",
    "            if log[1] == \"ray:acquire_lock\" and log[2] == 1: \n",
    "                start_lock = log[0]\n",
    "            if log[1] == \"ray:acquire_lock\" and log[2] == 2: \n",
    "                end_lock = log[0]\n",
    "        if start_exec != -1 and end_exec != -1 and start_store != -1 and end_store != -1 and start_lock != -1 and end_lock != -1:\n",
    "            profiles_dict[task_id] = dict()\n",
    "            exec_dur = end_exec - start_exec\n",
    "            store_dur = end_store - start_store\n",
    "            lock_dur = end_lock - start_lock\n",
    "            overall_dur = overall_end - overall_start \n",
    "            profiles_dict[task_id][\"execute\"] = exec_dur\n",
    "            profiles_dict[task_id][\"store\"] = store_dur\n",
    "            profiles_dict[task_id][\"acquire_lock\"] = lock_dur\n",
    "            profiles_dict[task_id][\"total\"] = overall_dur\n",
    "            profiles_dict[task_id][\"other\"] = overall_dur - exec_dur - store_dur - lock_dur\n",
    "results_table = pd.DataFrame.from_dict(profiles_dict)\n",
    "qgrid.show_grid(results_table.T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_acq = 0\n",
    "total_exec = 0\n",
    "total_store = 0\n",
    "total_other = 0\n",
    "total = 0\n",
    "for value in profiles_dict.values(): \n",
    "    total_exec += value[\"execute\"]\n",
    "    total_acq += value[\"acquire_lock\"]\n",
    "    total_store += value[\"store\"]\n",
    "    total_other += value[\"other\"]\n",
    "    total += value[\"total\"]\n",
    "\n",
    "labels = 'Acquire Lock', 'Execute', 'Store', 'Other'\n",
    "sizes = [total_acq/total, total_exec/total, total_store/total, total_other/total]\n",
    "explode = (0, 0.1, 0, 0)\n",
    "plt.pie(sizes, explode=explode, labels=labels, shadow=True, startangle=140)\n",
    "plt.axis('equal')\n",
    "print(\"Overall Task Breakdowns:\")\n",
    "print(\"Acquire Lock: \" + str(total_acq/total * 100) + \"%\")\n",
    "print(\"Execute: \" + str(total_exec/total * 100) + \"%\")\n",
    "print(\"Store outputs: \" + str(total_store/total * 100) + \"%\")\n",
    "print(\"Other: \" + str(total_other/total * 100) + \"%\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event Profiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event_list = []\n",
    "\n",
    "# Get and decode all task timing/event logs\n",
    "for key in rc.keys(\"event_log*\"):\n",
    "    content = rc.lrange(key, 0, -1)\n",
    "    event_list.append(json.loads(content[0])) \n",
    "    \n",
    "from collections import defaultdict\n",
    "\n",
    "# event_dict is used to store timing info\n",
    "event_dict = defaultdict(lambda: np.full(len(event_list), np.nan))\n",
    "\n",
    "# info_dict is used to store meta data - such as function names and task id\n",
    "info_dict = defaultdict(lambda: [None] * len(event_list))\n",
    "\n",
    "for i, task_event in enumerate(event_list):\n",
    "    for event in (task_event):\n",
    "        time, label, startstop, info = event\n",
    "        event_dict[(label, startstop)][i] = time\n",
    "        if info:\n",
    "            for k in info:\n",
    "                info_dict[k][i] = info[k]\n",
    "\n",
    "edf = pd.DataFrame(dict(event_dict))\n",
    "edf.rename(columns={1: 'start', 2:'end'}, inplace=True)\n",
    "edf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stragglers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event_names = rc.keys(\"event_log*\")\n",
    "x = 10\n",
    "stragglers = dict()\n",
    "\n",
    "for i in range(len(event_names)):\n",
    "    event_list = rc.lrange(event_names[i], 0, -1)\n",
    "    for event in event_list:\n",
    "        event_dict = json.loads(event)\n",
    "        task_id = \"\"\n",
    "        overall_start = event_dict[0][0]\n",
    "        overall_end = event_dict[len(event_dict)-1][0]\n",
    "        overall_dur = overall_end - overall_start\n",
    "        exec_start = -1\n",
    "        exec_end = -1\n",
    "        exec_dur = -1\n",
    "        for element in event_dict:\n",
    "            if element[1] == \"ray:task:execute\" and element[2] == 1:\n",
    "                exec_start = element[0]\n",
    "            if element[1] == \"ray:task:execute\" and element[2] == 2:\n",
    "                exec_end = element[0]\n",
    "            if \"task_id\" in element[3]:\n",
    "                task_id = element[3][\"task_id\"]\n",
    "        if exec_start != -1 and exec_end != -1 and task_id != \"\":\n",
    "            exec_dur = exec_end - exec_start\n",
    "            if len(stragglers.keys()) < x:\n",
    "                stragglers[task_id] = exec_dur\n",
    "            if len(stragglers.keys()) == x:\n",
    "                shortest_time = min(stragglers.values()) \n",
    "                for tid, time in stragglers.items(): \n",
    "                    if time == shortest_time: \n",
    "                        del[tid] \n",
    "                        stragglers[task_id] = exec_dur \n",
    "                        break\n",
    "results_table = pd.DataFrame(stragglers, index = [0])\n",
    "qgrid.show_grid(results_table.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstructed Task Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event_names = rc.keys(\"event_log*\")\n",
    "attempted = dict()\n",
    "reconstructed = dict()\n",
    "for i in range(len(event_names)):\n",
    "    event_list = rc.lrange(event_names[i], 0, -1)\n",
    "    for event in event_list:\n",
    "        event_dict = json.loads(event)\n",
    "        task_id = \"\"\n",
    "        for element in event_dict:\n",
    "            if \"task_id\" in element[3]:\n",
    "                task_id = element[3][\"task_id\"]\n",
    "        if task_id != \"\":\n",
    "            if task_id in attempted:\n",
    "                if task_id not in reconstructed:\n",
    "                    reconstructed[task_id] = 0\n",
    "                    reconstructed[task_id] += 1\n",
    "                else:\n",
    "                    attempted[task_id] = True\n",
    "results_table = pd.DataFrame(reconstructed)\n",
    "qgrid.show_grid(results_table)\n",
    "# include objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. System State\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using the global state API, we can populate a DataFrame with a list of Redis Clients currently connected\n",
    "ctable = ray.global_state.client_table()\n",
    "\n",
    "client_list = []\n",
    "for node_ip in ctable:\n",
    "    for client in ctable[node_ip]:\n",
    "        client[\"node_ip_address\"] = node_ip\n",
    "        client_list.append(client)\n",
    "\n",
    "client_df = pd.DataFrame(client_list)\n",
    "qgrid.show_grid(client_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can populate a DataFrame with a list of objects in the object store\n",
    "object_dict = {oid.hex(): v for oid, v in ray.global_state.object_table().items()}\n",
    "object_df = pd.DataFrame(object_dict).transpose()\n",
    "qgrid.show_grid(object_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object - Worker Placement Information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Objects associated with each worker_id \n",
    "object_table = ray.global_state.object_table()\n",
    "location_to_objects = dict()\n",
    "\n",
    "for object_id, object_descriptor in object_table.items():\n",
    "    if object_descriptor[\"ManagerIDs\"] != None: \n",
    "        for location in object_descriptor[\"ManagerIDs\"]:\n",
    "            if location not in location_to_objects:\n",
    "                location_to_objects[location] = []\n",
    "            object_id = str(object_id)\n",
    "            obj_comp = object_id.split(\"(\")\n",
    "            obj_comps = obj_comp[1].split(\")\") \n",
    "            object_id = obj_comps[0]\n",
    "            location_to_objects[location].append(object_id)\n",
    "table = pd.DataFrame.from_dict(location_to_objects)\n",
    "qgrid.show_grid(table)\n",
    "# object id -> worker id \n",
    "# skew in how objects are distributed \n",
    "# physical nodes -> total amt data on node, num tasks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worker Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "workers = rc.keys(\"Worker*\") \n",
    "worker_info = dict()\n",
    "for worker in workers:\n",
    "    worker_key_str = worker[len('Workers:'):]\n",
    "    worker_key_bytes = worker_key_str.encode('latin-1')\n",
    "    worker_info['Workers:{}'.format(hex_identifier(worker_key_bytes))] = rc.hgetall(worker)\n",
    "table = pd.DataFrame.from_dict(worker_info)\n",
    "qgrid.show_grid(table.T)\n",
    "# resource info for each physical node \n",
    "# double check the IP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Transfer Information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_files = ray.global_state.log_files()\n",
    "transferred = dict()\n",
    "for addr, inner_dict in log_files.items(): \n",
    "    for filename, contents in inner_dict.items(): \n",
    "        if \"plasma_manager\" in filename and \".out\" in filename:\n",
    "            cont = str(contents).split(\"ObjectID: \") \n",
    "            cont2 = cont[1].split(\"\\\\n\")\n",
    "            if cont2[0] not in transferred:\n",
    "                transferred[cont2[0]] = 0 \n",
    "            transferred[cont2[0]] += 1 \n",
    "table = pd.DataFrame(transferred, index = [0]) \n",
    "qgrid.show_grid(table.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Error Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Profiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event_names = rc.keys(\"event_log*\")\n",
    "error_profiles = dict()\n",
    "for i in range(len(event_names)):\n",
    "    event_list = rc.lrange(event_names[i], 0, -1)\n",
    "    for event in event_list:\n",
    "        event_dict = json.loads(event)\n",
    "        task_id = \"\"\n",
    "        traceback = \"\"\n",
    "        worker_id = \"\"\n",
    "        start_time = -1\n",
    "    for element in event_dict:\n",
    "        if element[1] == \"ray:task:execute\" and element[2] == 1:\n",
    "            start_time = element[0]\n",
    "        if \"task_id\" in element[3] and \"worker_id\" in element[3]:\n",
    "            task_id = element[3][\"task_id\"]\n",
    "            worker_id = element[3][\"worker_id\"]\n",
    "        if \"traceback\" in element[3]:\n",
    "            traceback = element[3][\"traceback\"]\n",
    "        if task_id != \"\" and worker_id != \"\" and traceback != \"\":\n",
    "            if start_time != -1:\n",
    "                error_profiles[task_id] = dict()\n",
    "                error_profiles[task_id][\"worker_id\"] = worker_id\n",
    "                error_profiles[task_id][\"traceback\"] = traceback\n",
    "                error_profiles[task_id][\"start_time\"] = start_time\n",
    "table = pd.DataFrame.from_dict(error_profiles) \n",
    "qgrid.show_grid(table.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Parallelization Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallelization Score: \n",
      "1.2988097921150623e-12\n"
     ]
    }
   ],
   "source": [
    "event_names = rc.keys(\"event_log*\")\n",
    "total_exec = 0\n",
    "earliest_start = float(\"inf\")\n",
    "latest_end = -1\n",
    "for i in range(len(event_names)):\n",
    "    event_list = rc.lrange(event_names[i], 0, -1)\n",
    "    for event in event_list:\n",
    "        event_dict = json.loads(event)\n",
    "        start_point = 00125\n",
    "        \n",
    "        end_point = 0\n",
    "        for element in event_dict:\n",
    "            if element[1] == \"ray:task:execute\" and element[2] == 1:\n",
    "                start_point = element[0]\n",
    "            if start_point < earliest_start:\n",
    "                earliest_start = start_point\n",
    "            if element[1] == \"ray:task:execute\" and element[2] == 2:\n",
    "                end_point = element[0]\n",
    "            if end_point > latest_end:\n",
    "                latest_end = end_point\n",
    "        total_exec += (end_point - start_point)\n",
    "job_dur = latest_end - earliest_start\n",
    "table = ray.global_state.client_table()\n",
    "total_cpus = 0\n",
    "for key, value in table.items():\n",
    "    for element in range(len(value)):\n",
    "        if \"NumCPUs\" in value[element]:\n",
    "            total_cpus += table[key][element][\"NumCPUs\"]\n",
    "if total_exec != None and job_dur != None: \n",
    "    print(\"Parallelization Score: \")\n",
    "    print ((total_exec) / (total_cpus * job_dur))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Task Interactive Queries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-78518e0126ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m     )\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m# movies[\"color\"] = np.where(movies[\"Oscars\"] > 0, \"orange\", \"grey\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-78518e0126ef>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m#p.title.text = \"%d movies selected\" % len(df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     source.data = dict(\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"color\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import pandas.io.sql as psql\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.layouts import layout, widgetbox\n",
    "from bokeh.models import ColumnDataSource, HoverTool, Div\n",
    "from bokeh.models.widgets import Slider, Select, TextInput\n",
    "from bokeh.io import curdoc\n",
    "\n",
    "prof1 = dict() \n",
    "tid = 2\n",
    "prof1[tid] = dict()\n",
    "prof1[tid][\"worker_id\"] = 1\n",
    "prof1[tid][\"execute\"] = 10\n",
    "prof1[tid][\"store\"] = 5 \n",
    "prof1[tid][\"errored\"] = False \n",
    "\n",
    "prof2 = dict() \n",
    "tid = 1\n",
    "prof1[tid] = dict()\n",
    "prof1[tid][\"worker_id\"] = 3\n",
    "prof1[tid][\"execute\"] = 5\n",
    "prof1[tid][\"store\"] = 15 \n",
    "prof1[tid][\"errored\"] = False\n",
    "\n",
    "profiles = [prof1, prof2]\n",
    "axis_map = {\n",
    "    \"Time\": \"Time\",\n",
    "    \"Workers\": \"Worker\",\n",
    "    \"Get Task\": \"Reviews\",\n",
    "    \"Box Office (dollars)\": \"BoxOffice\",\n",
    "    \"Length (minutes)\": \"Runtime\",\n",
    "    \"Year\": \"Year\",\n",
    "}\n",
    "\n",
    "hover = HoverTool(tooltips=[\n",
    "    (\"Title\", \"@title\"),\n",
    "    (\"Year\", \"@year\"),\n",
    "    (\"$\", \"@revenue\")\n",
    "])\n",
    "exec_time = Slider(title=\"Time to execute:\", value=50, start=0, end=1000000, step=10)\n",
    "store_time = Slider(title=\"Time to store outputs:\", value=50, start=0, end=1000000, step=10)\n",
    "x_axis = Select(title=\"X Axis\", options=sorted(axis_map.keys()), value=\"Time\")\n",
    "y_axis = Select(title=\"Y Axis\", options=sorted(axis_map.keys()), value=\"Workers\")\n",
    "\n",
    "source = ColumnDataSource(data=dict(x=[], y=[], color=[], title=[], year=[], revenue=[], alpha=[]))\n",
    "p = figure(plot_height=600, plot_width=700, title=\"\", toolbar_location=None, tools=[hover])\n",
    "p.circle(x=\"x\", y=\"y\", source=source, size=7, color=\"color\", line_color=None, fill_alpha=\"alpha\")\n",
    "\n",
    "def select():\n",
    "    return profiles\n",
    "\n",
    "sizing_mode = 'fixed'  # 'scale_width' also looks nice with this example\n",
    "controls = [x_axis, y_axis]\n",
    "inputs = widgetbox(*controls, sizing_mode=sizing_mode)\n",
    "l = layout([\n",
    "    [inputs, p],\n",
    "], sizing_mode=sizing_mode)\n",
    "curdoc().add_root(l)\n",
    "curdoc().title = \"Tasks\"\n",
    "\n",
    "\n",
    "def update():\n",
    "    df = select()\n",
    "    x_name = axis_map[x_axis.value]\n",
    "    y_name = axis_map[y_axis.value]\n",
    "\n",
    "    p.xaxis.axis_label = x_axis.value\n",
    "    p.yaxis.axis_label = y_axis.value\n",
    "    #p.title.text = \"%d movies selected\" % len(df)\n",
    "    source.data = dict(\n",
    "        x=df[x_name],\n",
    "        y=df[y_name],\n",
    "        color=df[\"color\"],\n",
    "        title=df[\"Title\"],\n",
    "        year=df[\"Year\"],\n",
    "        revenue=df[\"revenue\"],\n",
    "        alpha=df[\"alpha\"],\n",
    "    )\n",
    "\n",
    "update()\n",
    "\n",
    "# movies[\"color\"] = np.where(movies[\"Oscars\"] > 0, \"orange\", \"grey\")\n",
    "# movies[\"alpha\"] = np.where(movies[\"Oscars\"] > 0, 0.9, 0.25)\n",
    "# movies.fillna(0, inplace=True)  # just replace missing values with zero\n",
    "# movies[\"revenue\"] = movies.BoxOffice.apply(lambda x: '{:,d}'.format(int(x)))\n",
    "\n",
    "# with open(join(dirname(__file__), \"razzies-clean.csv\")) as f:\n",
    "#     razzies = f.read().splitlines()\n",
    "# movies.loc[movies.imdbID.isin(razzies), \"color\"] = \"purple\"\n",
    "# movies.loc[movies.imdbID.isin(razzies), \"alpha\"] = 0.9\n",
    "\n",
    "# axis_map = {\n",
    "#     \"Time\": \"Time\",\n",
    "#     \"Workers\": \"Worker\",\n",
    "#     \"Get Task\": \"Reviews\",\n",
    "#     \"Box Office (dollars)\": \"BoxOffice\",\n",
    "#     \"Length (minutes)\": \"Runtime\",\n",
    "#     \"Year\": \"Year\",\n",
    "# }\n",
    "\n",
    "# desc = Div(text=open(join(dirname(__file__), \"description.html\")).read(), width=800)\n",
    "\n",
    "# # Create Input controls\n",
    "# reviews = Slider(title=\"Minimum number of reviews\", value=80, start=10, end=300, step=10)\n",
    "# min_year = Slider(title=\"Year released\", start=1940, end=2014, value=1970, step=1)\n",
    "# max_year = Slider(title=\"End Year released\", start=1940, end=2014, value=2014, step=1)\n",
    "# oscars = Slider(title=\"Minimum number of Oscar wins\", start=0, end=4, value=0, step=1)\n",
    "# boxoffice = Slider(title=\"Dollars at Box Office (millions)\", start=0, end=800, value=0, step=1)\n",
    "# genre = Select(title=\"Genre\", value=\"All\",\n",
    "#                options=open(join(dirname(__file__), 'genres.txt')).read().split())\n",
    "# director = TextInput(title=\"Director name contains\")\n",
    "# cast = TextInput(title=\"Cast names contains\")\n",
    "# x_axis = Select(title=\"X Axis\", options=sorted(axis_map.keys()), value=\"Time\")\n",
    "# y_axis = Select(title=\"Y Axis\", options=sorted(axis_map.keys()), value=\"Workers\")\n",
    "\n",
    "# # Create Column Data Source that will be used by the plot\n",
    "# source = ColumnDataSource(data=dict(x=[], y=[], color=[], title=[], year=[], revenue=[], alpha=[]))\n",
    "\n",
    "# hover = HoverTool(tooltips=[\n",
    "#     (\"Title\", \"@title\"),\n",
    "#     (\"Year\", \"@year\"),\n",
    "#     (\"$\", \"@revenue\")\n",
    "# ])\n",
    "\n",
    "# p = figure(plot_height=600, plot_width=700, title=\"\", toolbar_location=None, tools=[hover])\n",
    "# p.circle(x=\"x\", y=\"y\", source=source, size=7, color=\"color\", line_color=None, fill_alpha=\"alpha\")\n",
    "\n",
    "\n",
    "# def select_movies():\n",
    "#     genre_val = genre.value\n",
    "#     director_val = director.value.strip()\n",
    "#     cast_val = cast.value.strip()\n",
    "#     selected = movies[\n",
    "#         (movies.Reviews >= reviews.value) &\n",
    "#         (movies.BoxOffice >= (boxoffice.value * 1e6)) &\n",
    "#         (movies.Year >= min_year.value) &\n",
    "#         (movies.Year <= max_year.value) &\n",
    "#         (movies.Oscars >= oscars.value)\n",
    "#     ]\n",
    "#     if (genre_val != \"All\"):\n",
    "#         selected = selected[selected.Genre.str.contains(genre_val)==True]\n",
    "#     if (director_val != \"\"):\n",
    "#         selected = selected[selected.Director.str.contains(director_val)==True]\n",
    "#     if (cast_val != \"\"):\n",
    "#         selected = selected[selected.Cast.str.contains(cast_val)==True]\n",
    "#     return selected\n",
    "\n",
    "\n",
    "# def update():\n",
    "#     df = select_movies()\n",
    "#     x_name = axis_map[x_axis.value]\n",
    "#     y_name = axis_map[y_axis.value]\n",
    "\n",
    "#     p.xaxis.axis_label = x_axis.value\n",
    "#     p.yaxis.axis_label = y_axis.value\n",
    "#     p.title.text = \"%d movies selected\" % len(df)\n",
    "#     source.data = dict(\n",
    "#         x=df[x_name],\n",
    "#         y=df[y_name],\n",
    "#         color=df[\"color\"],\n",
    "#         title=df[\"Title\"],\n",
    "#         year=df[\"Year\"],\n",
    "#         revenue=df[\"revenue\"],\n",
    "#         alpha=df[\"alpha\"],\n",
    "#     )\n",
    "\n",
    "# controls = [reviews, boxoffice, genre, min_year, max_year, oscars, director, cast, x_axis, y_axis]\n",
    "# for control in controls:\n",
    "#     control.on_change('value', lambda attr, old, new: update())\n",
    "\n",
    "# sizing_mode = 'fixed'  # 'scale_width' also looks nice with this example\n",
    "\n",
    "# inputs = widgetbox(*controls, sizing_mode=sizing_mode)\n",
    "# l = layout([\n",
    "#     [desc],\n",
    "#     [inputs, p],\n",
    "# ], sizing_mode=sizing_mode)\n",
    "\n",
    "# update()  # initial load of the data\n",
    "\n",
    "# curdoc().add_root(l)\n",
    "# curdoc().title = \"Tasks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
